{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJBNlvcCUz0p"
   },
   "source": [
    "Generative Adversarial Networks (GANs)\n",
    "======================================\n",
    "This code implements a Deep Convolutional GAN (DCGAN), a GAN with only convolutional layers in the encoder and decoder. If using Google Colab, please activate the use of the GPU (Edit -> Notebok Settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJ8BvMMjv1te"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INp84ckeUz0u",
    "outputId": "e691b936-24a1-4c03-bf4a-f47b77b5aaa3"
   },
   "outputs": [],
   "source": [
    "# install pytorch (http://pytorch.org/) and tqdm if run from Google Colaboratory\n",
    "import sys\n",
    "if 'google.colab' in sys.modules and 'torch' not in sys.modules:\n",
    "    !pip3 install torch torchvision #--index-url https://download.pytorch.org/whl/cu118  #uncomment to enforce cuda 11.8\n",
    "if 'google.colab' in sys.modules and 'tqdm' not in sys.modules:\n",
    "    !pip3 install tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(f\"Using Pytorch {torch.__version__}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-OAGgsUUz0w"
   },
   "source": [
    "Parameter Settings\n",
    "-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAJdBZZuUz0x"
   },
   "outputs": [],
   "source": [
    "latent_dim = 10       # latent dimension\n",
    "num_epochs = 50       # number of training epochs\n",
    "batch_size = 512      # batch size (you may increase it to gain time, but check not to\n",
    "                      # exceed your GPU memory limit)\n",
    "learning_rate = 1e-3  # learning rate of the training algorithm\n",
    "use_gpu = True        # use the GPU (strongly recommended for speed)\n",
    "compile = False       # not well implemented on Colab (requires a personal installation with a\n",
    "                      # relatively recent CUDA-compatible GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shmuCPIeUz0x"
   },
   "source": [
    "MNIST Data Loading\n",
    "-------------------\n",
    "\n",
    "MNIST images show digits from 0-9 in 28x28 grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMJ0HXu1Uz0y",
    "outputId": "ccc23be6-7263-43aa-f1f4-52754a15ccab"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "img_transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "mnist_dims = train_dataloader.dataset[0][0].shape[1:]\n",
    "mnist_dim = train_dataloader.dataset[0][0].numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar7unGj1Uz0y"
   },
   "source": [
    "Vanilla GAN\n",
    "-----------\n",
    "We define here the architecture of the different elements of the model. The init defines the different layers and the forward defines what happens when the model is called. We refer to it as the vanilla GAN as it the model in a very simple form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5WwpJosUz0z"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 256)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, mnist_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.tanh(self.fc4(x))\n",
    "        return x.view(-1, *mnist_dims)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(mnist_dim, 1024)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        return torch.sigmoid(self.fc4(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "NScLYNsav1IJ"
   },
   "source": [
    "We can now instantiate and load the model onto the GPU if relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9spB3vpv1IK",
    "outputId": "5f48810b-8cd5-4099-87af-cd5ca9ee6ba9"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if compile:\n",
    "  generator = torch.compile(generator)\n",
    "  discriminator = torch.compile(discriminator)\n",
    "  print(\"Using a compiled model (faster).\")\n",
    "\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "  print(\"Using the GPU (faster).\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"Using the CPU.\")\n",
    "\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "num_params_gen = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
    "num_params_disc = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
    "print('Number of parameters for generator: %d and discriminator: %d' % (num_params_gen, num_params_disc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UzOfOkWUz00"
   },
   "source": [
    "Training\n",
    "--------\n",
    "Be careful, the training can be relatively long, even with a GPU on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfDU_YB-Uz00",
    "outputId": "98c6c1df-2558-411f-ecd5-191f360cc0bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GAN training can be unstable. In this case, the strong momentum\n",
    "# for the gradient prevents convergence. One possible explanation is that the\n",
    "# strong momentum does not allow the two players in the adversarial game to react\n",
    "# to each other quickly enough. Decreasing beta1 (the exponential decay for the\n",
    "# gradient moving average in [0,1], lower is faster decay) from the default 0.9\n",
    "# to 0.5 allows for quicker reactions.\n",
    "gen_optimizer = torch.optim.Adam(params=generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "disc_optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# set to training mode\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "gen_loss_avg = []\n",
    "disc_loss_avg = []\n",
    "\n",
    "print('Training...')\n",
    "for epoch in range(num_epochs):\n",
    "    gen_loss_avg.append(0)\n",
    "    disc_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "\n",
    "    for image_batch, _ in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\", position=0, leave=True):\n",
    "        # moving the batch onto GPU if relevant\n",
    "        image_batch = image_batch.to(device)\n",
    "\n",
    "        # get dataset image and create real and fake labels for use in the loss\n",
    "        label_real = torch.ones(image_batch.size(0), device=device)\n",
    "        label_fake = torch.zeros(image_batch.size(0), device=device)\n",
    "\n",
    "        # generate a batch of images from samples of the latent prior\n",
    "        latent = torch.randn(image_batch.size(0), latent_dim, device=device)\n",
    "        fake_image_batch = generator(latent)\n",
    "\n",
    "        # train discriminator to correctly classify real and fake\n",
    "        # (detach the computation graph of the generator and the discriminator,\n",
    "        # so that gradients are not backpropagated into the generator)\n",
    "        real_pred = discriminator(image_batch).squeeze()\n",
    "        fake_pred = discriminator(fake_image_batch.detach()).squeeze()\n",
    "        disc_loss = 0.5 * (\n",
    "            F.binary_cross_entropy(real_pred, label_real) +\n",
    "            F.binary_cross_entropy(fake_pred, label_fake))\n",
    "\n",
    "        disc_optimizer.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        disc_optimizer.step()\n",
    "\n",
    "        # train generator to output an image that is classified as real\n",
    "        fake_pred = discriminator(fake_image_batch).squeeze()\n",
    "        gen_loss = F.binary_cross_entropy(fake_pred, label_real)\n",
    "\n",
    "        gen_optimizer.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        gen_loss_avg[-1] += gen_loss.item()\n",
    "        disc_loss_avg[-1] += disc_loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    gen_loss_avg[-1] /= num_batches\n",
    "    disc_loss_avg[-1] /= num_batches\n",
    "    print(f\"\\tAverage loss generator vs. discrim.: {gen_loss_avg[-1]:.3} vs. {disc_loss_avg[-1]:.3}\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDv7ZCQJFzZw"
   },
   "source": [
    "You may save the obtained weights after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnMG0oSEF9ZP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./pretrained'):\n",
    "  os.mkdir('./pretrained')\n",
    "\n",
    "torch.save(generator.state_dict(), './pretrained/my_vanilla_gan_generator.pth')\n",
    "torch.save(discriminator.state_dict(), './pretrained/my_vanilla_gan_discriminator.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9qI3s1kGCWK"
   },
   "source": [
    "If already saved, they can be loaded in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20MEdFyXGHdh",
    "outputId": "e30dc993-030f-4b2b-d50c-8723b44b4312"
   },
   "outputs": [],
   "source": [
    "# first load your model to generate instances of the generator and discriminator (but don't train it)\n",
    "generator.load_state_dict(torch.load('./pretrained/my_vanilla_gan_generator.pth'))\n",
    "discriminator.load_state_dict(torch.load('./pretrained/my_vanilla_gan_discriminator.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHA0uCwVUz01"
   },
   "source": [
    "Training Curves\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "7aBm_gNDUz01",
    "outputId": "edcddb62-2d3f-45a7-a450-3aebdec1aa43"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.semilogy(gen_loss_avg, label='Generator')\n",
    "plt.semilogy(disc_loss_avg, label='Discriminator')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou_gwNVBUz03"
   },
   "source": [
    "Interpolate in Latent Space\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "WX0QZ2Q3Uz03",
    "outputId": "e3ade92a-c19a-4cac-c5b1-dddd3b66e6e4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "import torchvision.utils\n",
    "\n",
    "generator.eval()\n",
    "\n",
    "def interpolation(lambda1, model, latent_1, latent_2):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # interpolation of the two latent vectors\n",
    "        inter_latent = lambda1 * latent_1 + (1 - lambda1) * latent_2\n",
    "\n",
    "        # reconstruct interpolated image\n",
    "        inter_latent = inter_latent.to(device)\n",
    "        inter_image = model(inter_latent)\n",
    "        inter_image = inter_image.cpu()\n",
    "\n",
    "        return inter_image\n",
    "\n",
    "# sample two latent vectors from the standard normal distribution\n",
    "latent_1 = torch.randn(1, latent_dim, device=device)\n",
    "latent_2 = torch.randn(1, latent_dim, device=device)\n",
    "\n",
    "# interpolation lambdas\n",
    "lambda_range=np.linspace(0,1,5)\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(15, 3))\n",
    "fig.subplots_adjust(wspace=.1)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for ind, l in enumerate(lambda_range):\n",
    "    inter_image=interpolation(float(l), generator, latent_1, latent_2)\n",
    "\n",
    "    image = inter_image.numpy()\n",
    "\n",
    "    axs[ind].imshow(image[0,:,:].squeeze(), cmap='gray')\n",
    "    axs[ind].set_title('$\\lambda$='+str(round(l,1)))\n",
    "    axs[ind].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYj377tXUz04"
   },
   "source": [
    "Sample Latent Vector from Prior (GAN as Generator)\n",
    "-------------------------------------------------\n",
    "\n",
    "GANs usually generate higher-quality results than VAEs or plain Autoencoders, since the distribution of generated digits is more focused on the modes of the real data distribution (see tutorial slides). However, they are harder to train and don't have an encoder, which means the inference of a latent code from a given image is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "G0UmIJLPUz04",
    "outputId": "232e4391-f844-4020-d8eb-09a0cc336afb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "import torchvision.utils\n",
    "\n",
    "generator.eval()\n",
    "n = 8\n",
    "\n",
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    # sample latent vectors from the standard normal distribution\n",
    "    latent = torch.randn(n**2, latent_dim, device=device)\n",
    "    fake_image_batch = generator(latent)\n",
    "    if len(fake_image_batch.shape) == 3:\n",
    "        fake_image_batch = fake_image_batch.unsqueeze(1)\n",
    "    fake_image_batch = fake_image_batch.cpu()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    show_image(torchvision.utils.make_grid(fake_image_batch.data,nrow=n))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "yskBlUrhv1IM"
   },
   "source": [
    "A CNN as Backbone\n",
    "-----------------\n",
    "We use a convolutional generator and discriminator, which generally gives better performance than fully connected versions that have the same number of parameters. Running this will shadow the alternative vanilla version above. You will still need to instantiate it.\n",
    "\n",
    "Kernel size 4 is used to avoid biasing problems described here: https://distill.pub/2016/deconv-checkerboard/\n",
    "\n",
    "Don't hesitate to tweak the architecture to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcPLMmJwv1IM"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(latent_dim, latent_dim * 32, 5, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(latent_dim * 32)\n",
    "        self.deconv2 = nn.ConvTranspose2d(latent_dim * 32, latent_dim * 16, 5, 1, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(latent_dim * 16)\n",
    "        self.deconv3 = nn.ConvTranspose2d(latent_dim * 16, latent_dim, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(latent_dim)\n",
    "        self.deconv4 = nn.ConvTranspose2d(latent_dim, 1, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, :, None, None]\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = torch.tanh(self.deconv4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, latent_dim, 4, 2, 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(latent_dim)\n",
    "        self.conv2 = nn.Conv2d(latent_dim, latent_dim * 16, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(latent_dim * 16)\n",
    "        self.conv3 = nn.Conv2d(latent_dim * 16, latent_dim * 32, 5, 1, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(latent_dim * 32)\n",
    "        self.conv4 = nn.Conv2d(latent_dim * 32, latent_dim, 5, 1, 0)\n",
    "        self.conv4_bn = nn.BatchNorm2d(latent_dim)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(latent_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1_bn(self.conv1(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = torch.sigmoid(self.fc(self.flatten(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "RfhnCBD_v1IM"
   },
   "source": [
    "Again, you can save and load the trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymTU1iH_v1IM"
   },
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), './pretrained/my_cnn_gan_generator.pth')\n",
    "torch.save(discriminator.state_dict(), './pretrained/my_cnn_gan_discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcjG8TBHv1IM",
    "outputId": "93479bd2-8d41-4e44-9a36-1d3a2961ac1a"
   },
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load('./pretrained/my_cnn_gan_generator.pth'))\n",
    "discriminator.load_state_dict(torch.load('./pretrained/my_cnn_gan_discriminator.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "J6ZBR1q8v1IM"
   },
   "source": [
    "You can now have a look at the results of the model by running again the corresponding sections."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
