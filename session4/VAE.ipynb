{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j47JY0uTYU52"
   },
   "source": [
    "Variational Auto-Encoders\n",
    "=========================\n",
    "This code implements a Variation Auto-Encoder (VAE). If using Google Colab, please activate the use of the GPU (Edit -> Notebok Settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ow0Kh-EZYoPy",
    "outputId": "1cebd6c6-f2b8-4e79-f4be-13eacc289bd9"
   },
   "outputs": [],
   "source": [
    "# install pytorch (http://pytorch.org/) if run from Google Colaboratory\n",
    "import sys\n",
    "if 'google.colab' in sys.modules and 'torch' not in sys.modules:\n",
    "    !pip3 install torch torchvision #--index-url https://download.pytorch.org/whl/cu118 #uncomment to enforce cuda 11.8\n",
    "\n",
    "if 'google.colab' in sys.modules and 'tqdm' not in sys.modules:\n",
    "    !pip3 install tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import os\n",
    "if os.path.exists('./training') == False:\n",
    "  os.mkdir('./training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z30nZkbuY9xX"
   },
   "source": [
    "Hyper-Parameters\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9S2rVJ6pY_-8"
   },
   "outputs": [],
   "source": [
    "batch_size = 3000     # batch size\n",
    "latent_dim = 100      # latent-space dimension\n",
    "middle_dim = 128      # size of the middle layer\n",
    "learning_rate = 1e-3  # learning rate\n",
    "max_epochs = 50       # maximum number of epochs\n",
    "use_gpu = True        # using the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03u5OrHuZOcc"
   },
   "source": [
    "Loading the Dataset\n",
    "-------------------\n",
    "As in the GAN example, we will be using the MNIST dataset. MNIST images show digits from 0-9 in 28x28 grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EQOZ5ezZVx_",
    "outputId": "ebecac33-4c44-419e-d5b1-3ef97ddc691d"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "img_transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# image dimensions\n",
    "input_dim = 28**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FvcF7AokK0u"
   },
   "source": [
    "VAE Definition\n",
    "--------------\n",
    "We will now use a specific scheme to initialize our weights, called Xavier initialization. You can neglect this if you are using other layers than fully connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gx_J05EVkV-f"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Yu8y7QSamnH"
   },
   "source": [
    "The following model represents the distribution encoder distribution q(z|x), together with the reparametrization trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_srXzGaBbGGF"
   },
   "outputs": [],
   "source": [
    "class Q(nn.Module):\n",
    "  def __init__(self, input_dim, middle_dim, latent_dim):\n",
    "    super(Q, self).__init__()\n",
    "    self.lin_middle = nn.Linear(input_dim, middle_dim, bias=True)\n",
    "    self.lin_mu = nn.Linear(middle_dim, latent_dim, bias=True)\n",
    "    self.lin_var = nn.Linear(middle_dim, latent_dim, bias=True)\n",
    "\n",
    "    # Xavier initialization (to be neglected if using other than fully-connected)\n",
    "    init_weights(self.lin_middle)\n",
    "    init_weights(self.lin_mu)\n",
    "    init_weights(self.lin_var)\n",
    "\n",
    "  def forward(self, input):\n",
    "    # forward\n",
    "    middle = F.relu(self.lin_middle(input))\n",
    "    z_mu = self.lin_mu(middle)\n",
    "    z_var = self.lin_var(middle)\n",
    "    return z_mu, z_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ADB4kdenMzu"
   },
   "source": [
    "We now model the reparametrization trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySUxXvDQnRSl"
   },
   "outputs": [],
   "source": [
    "class Reparametrization(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Reparametrization, self).__init__()\n",
    "\n",
    "  def forward(self, z_mu, z_var):\n",
    "    eps = torch.randn(z_var.size(0), z_var.size(1), device=device) # sample on a unit Gaussian\n",
    "    return z_mu + torch.exp(z_var/2) * eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6g8SKTFgHzT"
   },
   "source": [
    "The following model represents the decoder P(x|z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOJqtQJAgplb"
   },
   "outputs": [],
   "source": [
    "class P(nn.Module):\n",
    "  def __init__(self, input_dim, middle_dim, latent_dim):\n",
    "    super(P, self).__init__()\n",
    "    self.lin_latent = nn.Linear(latent_dim, middle_dim, bias=True)\n",
    "    self.lin_middle = nn.Linear(middle_dim, input_dim, bias=True)\n",
    "\n",
    "    # Xavier initialization (to be neglected if using other than fully-connected)\n",
    "    init_weights(self.lin_latent)\n",
    "    init_weights(self.lin_middle)\n",
    "\n",
    "  def forward(self, latent):\n",
    "    middle = F.relu(self.lin_latent(latent))\n",
    "    return F.sigmoid(self.lin_middle(middle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v11VMJUuh6UA"
   },
   "source": [
    "Training\n",
    "--------\n",
    "\n",
    "We first initialize an instance of the model and load it onto GPU if relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgl4ZXgdiA4R",
    "outputId": "1800b001-1b39-41a8-b08e-ac6fad61e43f"
   },
   "outputs": [],
   "source": [
    "# creating instances of the model\n",
    "p = P(input_dim, middle_dim, latent_dim)\n",
    "q = Q(input_dim, middle_dim, latent_dim)\n",
    "reparam = Reparametrization()\n",
    "\n",
    "# loading them onto the GPU if relevant\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "  print(\"Using the GPU (faster).\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"Using the CPU.\")\n",
    "\n",
    "q = q.to(device)\n",
    "p = p.to(device)\n",
    "reparam = reparam.to(device)\n",
    "\n",
    "# computing the number of parameters\n",
    "num_params_gen = sum(param.numel() for param in p.parameters() if param.requires_grad)\n",
    "num_params_disc = sum(param.numel() for param in q.parameters() if param.requires_grad)\n",
    "print('Number of parameters for encoder: %d and decoder: %d' % (num_params_gen, num_params_disc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9zxficBiEvN"
   },
   "source": [
    "We can now do the training properly speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XF8fk1rUiGZf",
    "outputId": "a91facf8-3d2d-41f2-858f-1251652febce"
   },
   "outputs": [],
   "source": [
    "# set models to train mode\n",
    "p.train()\n",
    "q.train()\n",
    "reparam.train()\n",
    "\n",
    "parameters = list(p.parameters()) + list(q.parameters())\n",
    "optim = torch.optim.Adam(parameters, lr=learning_rate, betas=(0.5, 0.999))\n",
    "bce = nn.BCELoss(size_average=False, reduction='mean')\n",
    "\n",
    "total_losses = []\n",
    "recon_losses = []\n",
    "kl_losses = []\n",
    "current_image = 0\n",
    "\n",
    "print('Training...')\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "  avg_total_loss = 0\n",
    "  avg_recon_loss = 0\n",
    "  avg_kl_loss = 0\n",
    "\n",
    "  for _, (batch, _) in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch}\")):\n",
    "    batch = batch.to(device) # load the data onto GPU is relevant\n",
    "    batch = batch.view(batch_size, -1)\n",
    "\n",
    "    # forward\n",
    "    z_mu, z_var = q(batch)\n",
    "    z = reparam(z_mu, z_var)\n",
    "    batch_recon = p(z)\n",
    "\n",
    "    # reconstruction loss E[log P(X|z)]\n",
    "    recon_loss = bce(batch_recon, batch) / len(batch)\n",
    "    # distribution loss D_KL(Q(z|X) || P(z))\n",
    "    kl_loss = torch.mean(0.5 * torch.sum(torch.exp(z_var) + z_mu ** 2 - 1. - z_var, 1))\n",
    "    # Total loss\n",
    "    total_loss = recon_loss + kl_loss\n",
    "\n",
    "    # backward\n",
    "    total_loss.backward()\n",
    "\n",
    "    # update\n",
    "    optim.step()\n",
    "\n",
    "    # housekeeping\n",
    "    optim.zero_grad()\n",
    "    avg_total_loss += total_loss / len(batch)\n",
    "    avg_recon_loss += recon_loss / len(batch)\n",
    "    avg_kl_loss += kl_loss / len(batch)\n",
    "\n",
    "  # end of epoch\n",
    "  total_losses.append(avg_total_loss.item())\n",
    "  recon_losses.append(avg_recon_loss.item())\n",
    "  kl_losses.append(avg_kl_loss.item())\n",
    "  print(f\"\\t[Losses] Total {total_losses[-1]:.3} - Recon. {recon_losses[-1]:.3} - KL {kl_losses[-1]:.3}\")\n",
    "\n",
    "  # plot\n",
    "  if epoch % 2 == 0:\n",
    "        samples = p(z).data.cpu().numpy()[:16]\n",
    "\n",
    "        plt.close()\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('training/'):\n",
    "            os.makedirs('out/')\n",
    "        # plt.show()\n",
    "        # plt.pause(0.1)\n",
    "        plt.savefig('training/{}_{}.png'.format(epoch, str(current_image).zfill(3)), bbox_inches='tight')\n",
    "        current_image += 1\n",
    "        # plt.close(fig)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XziiVXMR0eFY"
   },
   "source": [
    "We can now plot the training curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "8Vz0u26a0g8j",
    "outputId": "0624380f-2ee3-4c3e-bd55-f19e410925b0"
   },
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.semilogy(total_losses, label='Total')\n",
    "plt.semilogy(recon_losses, label='Reconstruction')\n",
    "plt.semilogy(kl_losses, label='Kullback-Leibler')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8rKdm-oiHT1"
   },
   "source": [
    "Generation\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "oMMSrcl1iMW-",
    "outputId": "9b3a4593-2777-4636-dcfa-1bcc5955cbb3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "import torchvision.utils\n",
    "\n",
    "p.eval()\n",
    "n = 8\n",
    "\n",
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def correct_shape(imgs):\n",
    "  return imgs.view(n**2, 28, 28).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # sample latent vectors from the standard normal distribution\n",
    "    latent = torch.randn((n**2, latent_dim), device=device)\n",
    "    fake_image_batch = p(latent)\n",
    "    fake_image_batch = correct_shape(fake_image_batch)\n",
    "    fake_image_batch = fake_image_batch.cpu()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    show_image(torchvision.utils.make_grid(fake_image_batch.data,nrow=n))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtkLm1mZiMss"
   },
   "source": [
    "Visualization in Latent Space\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "dNLu3oNniQiu",
    "outputId": "03cb2a40-c725-4aa1-95b6-2d5920e64a10"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "import torchvision.utils\n",
    "\n",
    "p.eval()\n",
    "\n",
    "def correct_shape(imgs):\n",
    "  return imgs.view(-1, 28, 28).unsqueeze(1)\n",
    "\n",
    "def interpolation(lambda1, model, latent_1, latent_2):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # interpolation of the two latent vectors\n",
    "        inter_latent = lambda1* latent_1 + (1- lambda1) * latent_2\n",
    "\n",
    "        # reconstruct interpolated image\n",
    "        inter_latent = inter_latent.to(device)\n",
    "        inter_image = model(inter_latent)\n",
    "        inter_image = inter_image.cpu()\n",
    "\n",
    "        return inter_image\n",
    "\n",
    "# sample two latent vectors from the standard normal distribution\n",
    "latent_1 = torch.randn((1, latent_dim), device=device)\n",
    "latent_2 = torch.randn((1, latent_dim), device=device)\n",
    "\n",
    "# interpolation lambdas\n",
    "lambda_range=np.linspace(0,1,5)\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(15, 3))\n",
    "fig.subplots_adjust(wspace=.1)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for ind,l in enumerate(lambda_range):\n",
    "    inter_image=interpolation(float(l), p, latent_1, latent_2)\n",
    "\n",
    "    inter_image = correct_shape(inter_image)\n",
    "\n",
    "    image = inter_image.numpy()\n",
    "\n",
    "    axs[ind].imshow(image[0,0,:,:], cmap='gray')\n",
    "    axs[ind].set_title('$\\lambda$='+str(round(l,1)))\n",
    "    axs[ind].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ5o_qtH_4eC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
